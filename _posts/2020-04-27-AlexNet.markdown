---
layout: post
title:  "Image Classification (2) - AlexNet"
description: 
date:   2020-04-27 21:03:36 +0530
categories: DeepLearning ImageClassification
---
---

## Image Classification (2) -  AlexNet (2012)

---

2010년부터 Image Classification 대회가 매년 개최되었는데, 2012년 압도적인 성능으로 우승한 architecture가 AlexNet입니다.

---

### AlexNet의 구조

---

![Alexnet](https://i.imgur.com/l7J6lvu.png)


AlexNet의 architecture는 LeNet-5와 다르지 않습니다.

가장 큰 변화는 병렬연산을 수행하기 위해 병렬적인 architecture로 설계된 점입니다.

그 당시에, 1개의 GPU로 실험하기엔 memory가 부족하여 병렬적 구조로 설계하였습니다.

AlexNet은 8개의 layer로 구성되어 있습니다.

8개의 layer는 5개의 Convolution layer와 3개의 Fully-connected layr로 구성되어 있습니다.

architecture의 layer별로 자세히 알아보자.

---

### 1. input layer

224 x 224 크기의 RGB 3channel image를 input으로 사용합니다.

---

### 2. 1st layer(convolution layer)

96개의 11 x 11 x 3 size fliter로 input image를 conv해줍니다.

이때, conv stride는 4로 설정하였고 zero-padding은 사용하지 않았습니다.

> zero-padding : conv로 인한 feature map size가 축소되는 것을 방지하는 목적. 축소되는 정도를 줄이기 위해 image 가장자리에 0을 추가한다.

conv된 feature map(96장의 55 x 55 size)을 ReLU function으로 Activation해줍니다.

> ReLU function : Activation Function으로 기존에 사용하던 tanh보다 빠르게 수렴하는 효과를 얻음.

이어서, 3 x 3 overlapping max pooling을 stride 2로 수행합니다.

> overlapping max pooling : pooling의 filter size를 stride보다 크게 적용.

그 결과로, 27 x 27 x 96 feature map을 갖게 됩니다.

마지막으로, 수렴 속도를 높이기 위해 local response normalization을 수행합니다.

> local response normalization : 최근엔 거의 사용하지 않는 normalization technic

local response nomalization은 feature map의 dimension을 변화시키지 않으므로, feature map size는 27 x 27 x 96으로 유지됩니다.

첫번쨰 layer에 3가지의 AlexNet 주요 특징들이 녹아있습니다.

(1) ReLU

(2) Local Response normalization

(3) Overlapping Pooling

---

### 3. 2nd layer(convolution layer)

256개의 5 x 5 x 28 filter를 사용하여 1st layer output feature map을 conv해줍니다.

이 때, stride 1과 zero-padding 2로 적용합니다.

그 결과로, 27 x 27 x 256 feature map을 얻게 됩니다.

이어서, ReLU function을 Activation해줍니다.

그리고, 3 x 3 overlapping max pooling을 stride 2로 수행합니다.

그 결과로, 13 x 13 x 256 feature map을 얻게 됩니다.

마지막으로, local response normalization을 수행하여 13 x 13 x 256 feature map을 유지시킵니다.

---

### 4. 3rd layer(convolution layer)

384개의 3 x 3 x 256 filter를 사용하여 2nd layer output feature map을 conv해줍니다.

이 때, stride 1과 zero-padding 1로 적용합니다.

그 결과로, 13 x 13 x 384 feature map을 얻게 됩니다.

마지막으로, ReLU fuction을 activation해줍니다.

---

### 5. 4th layer(convolution layer)

384개의 3 x 3 x 192 filter를 사용하여 3rd layer output feature map을 conv해줍니다.

이 때, stride 1과 zero-padding 1로 적용합니다.

그 결과로, 13 x 13 x 384 feature map을 얻게 됩니다.

마지막으로, ReLU fuction을 activation해줍니다.

---

### 6. 5th layer(convolution layer)

256개의 3 x 3 x 192 filter를 사용하여 4th layer output feature map을 conv해줍니다.

이 때, stride 1과 zero-padding 1로 적용합니다.

그 결과로, 13 x 13 x 256 feature map을 얻게 됩니다.

그리고 ReLU function을 activaiton해줍니다.

마지막으로, 3 x 3 overlapping max pooling을 stride 2로 수행하여, 6 x 5 256 feature map을 얻게 됩니다.

---

### 7. 6th layer(fully connected layer)

5th layer output인 6 x 6 x 256 feature map을 flatten하여 6 x 6 x 256 = 9216 dimension vector로 만들어 줍니다.

이어서, 4096개의 뉴런과 fully connected해줍니다.

마지막으로, ReLU function을 activation해줍니다.

---

### 8. 7th layer(fully connected layer)

6th layer output feature map을 4096 뉴런과 fully connected해줍니다.

마지막으로, ReLU funtion activation해줍니다.

---

### 9. 8th layer(fully connected layer)

7th layer output feature map을 1000 뉴런과 fully connected해줍니다.

마지막으로, 1000개 뉴런의 output 값을 softmax function을 적용하여 1000개의 class에 속할 확률을 나타냅니다.

---

AlexNet은 약 6천만개의 parameter가 훈련되어야합니다.

LeNet-5에서 6만개의 parameter가 훈련되는 거보다 1000배 많아졌습니다.

그만큼 컴퓨팅 기술도 좋아졌고, 훈련시간을 줄이는 방법들이 사용되었기 때문입니다.

---

참고
1. [https://hoya012.github.io/blog/deeplearning-classification-guidebook-1/][1]
2. [https://bskyvision.com/421][2]

---

[1]: https://hoya012.github.io/blog/deeplearning-classification-guidebook-1/
[2]: https://bskyvision.com/421
